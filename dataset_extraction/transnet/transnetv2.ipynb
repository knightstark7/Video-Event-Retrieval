{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43db011a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-02T05:34:25.870630Z",
     "iopub.status.busy": "2023-10-02T05:34:25.869719Z",
     "iopub.status.idle": "2023-10-02T05:34:37.547401Z",
     "shell.execute_reply": "2023-10-02T05:34:37.546030Z"
    },
    "papermill": {
     "duration": 11.683675,
     "end_time": "2023-10-02T05:34:37.549342",
     "exception": false,
     "start_time": "2023-10-02T05:34:25.865667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in d:\\anaconda\\envs\\py310\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pillow in d:\\anaconda\\envs\\py310\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: future in d:\\anaconda\\envs\\py310\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "d:\\AIChallenge\\data_sotuyen1\\dataset_extraction\\transnet\\TransNetV2\\inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'TransNetV2'...\n",
      "Updating files:  48% (15/31)\n",
      "Updating files:  51% (16/31)\n",
      "Updating files:  54% (17/31)\n",
      "Updating files:  58% (18/31)\n",
      "Updating files:  61% (19/31)\n",
      "Updating files:  64% (20/31)\n",
      "Updating files:  67% (21/31)\n",
      "Updating files:  70% (22/31)\n",
      "Updating files:  74% (23/31)\n",
      "Updating files:  77% (24/31)\n",
      "Updating files:  80% (25/31)\n",
      "Updating files:  83% (26/31)\n",
      "Updating files:  87% (27/31)\n",
      "Updating files:  90% (28/31)\n",
      "Updating files:  93% (29/31)\n",
      "Updating files:  96% (30/31)\n",
      "Updating files: 100% (31/31)\n",
      "Updating files: 100% (31/31), done.\n",
      "Filtering content:  66% (2/3)\n",
      "Filtering content: 100% (3/3), 5.66 MiB | 1.44 MiB/s\n",
      "Filtering content: 100% (3/3), 34.77 MiB | 3.15 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python pillow\n",
    "!git clone https://github.com/soCzech/TransNetV2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4ede34-0aba-4d79-85d6-fe6444da5385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AIChallenge\\data_sotuyen1\\dataset_extraction\\transnet\\TransNetV2\\inference\n"
     ]
    }
   ],
   "source": [
    "%cd TransNetV2/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0e360e",
   "metadata": {
    "papermill": {
     "duration": 11.666998,
     "end_time": "2023-10-02T05:34:49.219467",
     "exception": false,
     "start_time": "2023-10-02T05:34:37.552469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda\\envs\\py310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import module\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import glob\n",
    "import ffmpeg\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transnetv2 import TransNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3ba54",
   "metadata": {
    "papermill": {
     "duration": 0.00263,
     "end_time": "2023-10-02T05:34:49.225383",
     "exception": false,
     "start_time": "2023-10-02T05:34:49.222753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse video info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fdda93",
   "metadata": {
    "papermill": {
     "duration": 0.010036,
     "end_time": "2023-10-02T05:34:49.238095",
     "exception": false,
     "start_time": "2023-10-02T05:34:49.228059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "videos_dir = 'D:/AIChallenge/data_sotuyen1/video'\n",
    "all_video_paths = dict()\n",
    "for part in sorted(os.listdir(videos_dir)):\n",
    "    data_part = part.split('_')[-1] # L01, L02 for ex\n",
    "    all_video_paths[data_part] =  dict()\n",
    "\n",
    "for data_part in sorted(all_video_paths.keys()):\n",
    "    data_part_path = f'{videos_dir}/Videos_{data_part}/video'\n",
    "    video_paths = sorted(os.listdir(data_part_path))\n",
    "    video_ids = [video_path.replace('.mp4', '').split('_')[-1] for video_path in video_paths]\n",
    "    for video_id, video_path in zip(video_ids, video_paths):\n",
    "        video_path_full = f'{data_part_path}/{video_path}'\n",
    "        all_video_paths[data_part][video_id] = video_path_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db50cd4-de70-4154-b087-62708f608850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L18': {}, 'L19': {'V001': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V001.mp4', 'V003': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V003.mp4', 'V004': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V004.mp4', 'V005': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V005.mp4', 'V006': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V006.mp4', 'V007': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V007.mp4', 'V008': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V008.mp4', 'V009': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V009.mp4', 'V010': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V010.mp4', 'V011': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V011.mp4', 'V012': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V012.mp4', 'V013': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V013.mp4', 'V014': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V014.mp4', 'V015': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V015.mp4', 'V016': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V016.mp4', 'V017': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V017.mp4', 'V018': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V018.mp4', 'V019': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V019.mp4', 'V020': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V020.mp4', 'V021': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V021.mp4', 'V022': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V022.mp4', 'V023': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V023.mp4', 'V024': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V024.mp4', 'V025': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V025.mp4', 'V026': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V026.mp4', 'V027': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V027.mp4', 'V028': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V028.mp4', 'V029': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V029.mp4', 'V030': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V030.mp4', 'V031': 'D:/AIChallenge/data_sotuyen1/video/Videos_L19/video/L19_V031.mp4'}, 'L22': {'V001': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V001.mp4', 'V002': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V002.mp4', 'V003': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V003.mp4', 'V004': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V004.mp4', 'V005': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V005.mp4', 'V006': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V006.mp4', 'V007': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V007.mp4', 'V008': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V008.mp4', 'V009': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V009.mp4', 'V010': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V010.mp4', 'V011': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V011.mp4', 'V012': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V012.mp4', 'V013': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V013.mp4', 'V014': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V014.mp4', 'V015': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V015.mp4', 'V016': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V016.mp4', 'V017': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V017.mp4', 'V018': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V018.mp4', 'V019': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V019.mp4', 'V020': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V020.mp4', 'V021': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V021.mp4', 'V022': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V022.mp4', 'V023': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V023.mp4', 'V024': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V024.mp4', 'V025': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V025.mp4', 'V026': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V026.mp4', 'V027': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V027.mp4', 'V028': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V028.mp4', 'V029': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V029.mp4', 'V030': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V030.mp4', 'V031': 'D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V031.mp4'}}\n"
     ]
    }
   ],
   "source": [
    "print( all_video_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990ca30",
   "metadata": {
    "papermill": {
     "duration": 0.002565,
     "end_time": "2023-10-02T05:34:49.330306",
     "exception": false,
     "start_time": "2023-10-02T05:34:49.327741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7989a995",
   "metadata": {
    "papermill": {
     "duration": 10.415343,
     "end_time": "2023-10-02T05:34:59.748321",
     "exception": false,
     "start_time": "2023-10-02T05:34:49.332978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Using weights from d:\\AIChallenge\\data_sotuyen1\\dataset_extraction\\transnet\\TransNetV2\\inference\\transnetv2-weights/.\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V020.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V021.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V022.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V023.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V024.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V025.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V026.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V027.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V028.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V029.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V030.mp4\n",
      "[TransNetV2] Extracting frames from D:/AIChallenge/data_sotuyen1/video/Videos_L22/video/L22_V031.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Processing video frames 27945/27945\n",
      "[TransNetV2] Processing video frames 29754/29754\n",
      "[TransNetV2] Processing video frames 31066/31066\n",
      "[TransNetV2] Processing video frames 31679/31679\n",
      "[TransNetV2] Processing video frames 31705/31705\n",
      "[TransNetV2] Processing video frames 33445/33445\n",
      "[TransNetV2] Processing video frames 33200/33200\n",
      "[TransNetV2] Processing video frames 33875/33875\n",
      "[TransNetV2] Processing video frames 34149/34149\n",
      "[TransNetV2] Processing video frames 34064/34064\n",
      "[TransNetV2] Processing video frames 38124/38124\n",
      "[TransNetV2] Processing video frames 38981/38981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [1:54:01<00:00, 570.16s/it]   \n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "model = TransNetV2()  # Khởi tạo model\n",
    "save_dir = 'D:/AIChallenge/data_sotuyen1/dataset_extraction/transnet/SceneJSON'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "def process_video(video_info):\n",
    "    key, video_id, video_path = video_info\n",
    "    # Dự đoán khung hình và các cảnh từ video\n",
    "    _, single_frame_predictions, _ = model.predict_video(video_path)\n",
    "    scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "    \n",
    "    # Tạo thư mục cho từng key\n",
    "    key_dir = os.path.join(save_dir, key)\n",
    "    os.makedirs(key_dir, exist_ok=True)\n",
    "    \n",
    "    # Lưu thông tin cảnh vào file JSON\n",
    "    with open(f\"{key_dir}/{video_id}.json\", 'w') as f:\n",
    "        json.dump(scenes.tolist(), f)\n",
    "\n",
    "# Lọc các video trong thư mục L22 từ V019 trở đi\n",
    "video_info_list = [\n",
    "    (key, video_id, video_paths_dict[video_id])\n",
    "    for key, video_paths_dict in all_video_paths.items()\n",
    "    if key == 'L22'  # Chỉ xử lý thư mục L22\n",
    "    for video_id in sorted(video_paths_dict.keys())\n",
    "    if video_id >= 'V020'  # Chỉ xử lý các video từ V019 trở đi\n",
    "]\n",
    "\n",
    "# Sử dụng ThreadPoolExecutor để xử lý song song\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(process_video, video_info_list), total=len(video_info_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbf3c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-02T10:22:37.935320Z",
     "iopub.status.busy": "2023-10-02T10:22:37.934810Z",
     "iopub.status.idle": "2023-10-02T10:22:39.030008Z",
     "shell.execute_reply": "2023-10-02T10:22:39.028471Z"
    },
    "papermill": {
     "duration": 1.841836,
     "end_time": "2023-10-02T10:22:39.032765",
     "exception": false,
     "start_time": "2023-10-02T10:22:37.190929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -r ./TransNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed7595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17307.259832,
   "end_time": "2023-10-02T10:22:45.041932",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-02T05:34:17.782100",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
